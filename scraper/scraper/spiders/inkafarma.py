import re
import scrapy
from scrapy_playwright.page import PageMethod
from scraper.items import ScraperItem
from scrapy.http import Response
from playwright.async_api import Page
import time

from .constants import inkafarma

class InkafarmaSpider(scrapy.Spider):
    name = "inkafarma"
    allowed_domains = ["inkafarma.pe"]
    
    def __init__(self, custom_urls=None, *args, **kwargs):
        super(InkafarmaSpider, self).__init__(*args, **kwargs)
        self.custom_urls = custom_urls  # Initialize custom_urls

        # Procesar URLs de entrada
        self.start_urls, self.subcategories = self._process_input_urls(custom_urls)
    
    def _process_input_urls(self, custom_urls):
        if custom_urls:
            urls = custom_urls.split(',') if isinstance(custom_urls, str) else custom_urls
            cleaned_urls = [url.strip() for url in urls]
            self.logger.info(f"Usando URLs personalizadas: {len(cleaned_urls)} URLs")
            return cleaned_urls, [None] * len(cleaned_urls)  # Return None for subcategories
        else:
            urls = []
            subcategories = []
            for categoria in inkafarma.CATEGORIAS:
                url = inkafarma.CATEGORIA_URL_TEMPLATE.format(categoria=categoria)
                urls.append(url)
                subcategories.append(categoria)
            self.logger.info(f"URLs generadas autom√°ticamente: {len(urls)} URLs")
            return urls, subcategories

    def start_requests(self):
        """Generar requests iniciales con configuraci√≥n de Playwright"""
        self.logger.info("üöÄ Iniciando scraping de InkaFarma con Playwright...")

        urls, subcategories = self._process_input_urls(self.custom_urls)
        for i, (url, subcategory) in enumerate(zip(urls, subcategories)):
            unique_url = f"{url}?scrapy_index={i}&ts={int(time.time())}"
            yield scrapy.Request(
                url=unique_url,
                callback=self.parse_category,
                meta={
                    "playwright": True,
                    "playwright_include_page": True,
                    "subcategory": subcategory,  # Pass subcategory in meta
                    "playwright_page_goto_kwargs": {
                        "wait_until": "domcontentloaded",  # Solo esperar DOM, no todos los recursos
                        "timeout": 30000,
                    },
                    "playwright_page_methods": [
                        PageMethod("wait_for_load_state", "domcontentloaded"),
                        PageMethod("wait_for_timeout", 5000),
                    ],
                },
                dont_filter=True
            )

    async def extract_menu_structure(self, page, category_prefix):
        """
        Extrae la estructura del men√∫ de InkaFarma usando una estrategia directa.
        En lugar de depender del hover, usa las categor√≠as conocidas de InkaFarma.
        """
        menu_structure = {}

        try:
            # Usar categor√≠as directas ya que el hover no funciona como esper√°bamos
            target_dept_url = f"https://inkafarma.pe/categoria/{category_prefix}"
            
            self.logger.info(f"üöÄ Navegando directamente al departamento: {target_dept_url}")
            await page.goto(target_dept_url, wait_until="domcontentloaded", timeout=30000)
            await page.wait_for_timeout(3000)
            
            # Verificar si la p√°gina carg√≥ correctamente
            page_title = await page.title()
            if "404" in page_title or "Not Found" in page_title:
                self.logger.warning(f"‚ö†Ô∏è Categor√≠a no encontrada: {target_dept_url}")
                return {}
            
            # Verificar si esta p√°gina tiene subcategor√≠as o productos directamente
            product_count = await self.get_product_count(page)
            self.logger.info(f"üìä Productos en departamento '{category_prefix}': {product_count}")
            
            if product_count >= 250:
                # Buscar subcategor√≠as en filtros laterales o en la p√°gina
                self.logger.info("üîç Buscando subcategor√≠as...")
                
                # Estrategia 1: Buscar enlaces de subcategor√≠as en filtros
                subcategory_links = await page.query_selector_all("a[href*='/categoria/']")
                categorias_data = []
                seen_urls = set()
                
                for subcat_link in subcategory_links:
                    href = await subcat_link.get_attribute("href")
                    text = await subcat_link.text_content()
                    
                    if href and href != f"/categoria/{category_prefix}" and category_prefix in href:
                        # Evitar duplicados
                        if href not in seen_urls:
                            seen_urls.add(href)
                            full_url = f"https://inkafarma.pe{href}" if href.startswith('/') else href
                            categorias_data.append({
                                "nombre": text.strip() if text else f"Subcategor√≠a {len(categorias_data)+1}",
                                "href": full_url,
                                "subcategorias": []
                            })
                self.logger.info(f"üìã Encontradas {len(categorias_data)} subcategor√≠as para '{category_prefix}'")
                
                if len(categorias_data) == 0:
                    self.logger.warning(f"‚ö†Ô∏è No se encontraron subcategor√≠as v√°lidas para '{category_prefix}'. Activando fallback...")
                    return {}  # Estructura vac√≠a para activar fallback
                
                menu_structure = {
                    "departamento": {
                        "nombre": category_prefix.replace("-", " ").title(),
                        "href": target_dept_url
                    },
                    "categorias": categorias_data
                }
            else:
                # Si tiene pocos productos, extraer directamente
                self.logger.info(f"‚úÖ Departamento '{category_prefix}' tiene {product_count} productos. Extrayendo directamente...")
                menu_structure = {
                    "departamento": {
                        "nombre": category_prefix.replace("-", " ").title(),
                        "href": target_dept_url
                    },
                    "categorias": [],
                    "extract_direct": True
                }

        except Exception as e:
            self.logger.error(f"‚ùå Error extrayendo estructura del men√∫ para '{category_prefix}': {e}")
            import traceback
            self.logger.error(f"üîç Traceback: {traceback.format_exc()}")

        return menu_structure

    async def parse_category(self, response):
        """Parsea una categor√≠a espec√≠fica - si >= 250 productos, extrae del men√∫ y navega directamente"""
        page = response.meta["playwright_page"]
        
        try:
            current_url = page.url
            self.logger.info(f"üöÄ Procesando categor√≠a: {current_url}")
            
            # Esperar a que se cargue la p√°gina inicial
            await page.wait_for_timeout(3000)

            # Verificar el n√∫mero de productos en la p√°gina
            product_count = await self.get_product_count(page)
            self.logger.info(f"üìä Productos encontrados en la categor√≠a: {product_count}")

            if product_count < 250:
                # Si hay menos de 250 productos, hacer scroll e extraer
                self.logger.info(f"‚úÖ {product_count} productos (<250). Extrayendo directamente...")
                await self.await_products_loaded(page)
                productos_cargados = await self.scroll_to_load_all_products(page)
                self.logger.info(f"‚úÖ Total productos cargados: {productos_cargados}")
                content = await page.content()
                await page.close()
                from scrapy.http import HtmlResponse
                updated_response = HtmlResponse(
                    url=response.url,
                    body=content,
                    encoding='utf-8'
                )
                for item in self.parse_products(updated_response):
                    yield item
            else:
                # Si hay >= 250 productos, extraer URLs del men√∫ y navegar a subcategor√≠as
                self.logger.info(f"üîÑ Detectados {product_count} productos (>=250). Buscando subcategor√≠as en el men√∫...")
                
                category_name = self.extract_category_from_url(current_url)
                category_prefix = category_name[:4].lower()
                self.logger.info(f"üîç Buscando departamento que empiece con: '{category_prefix}'")
                
                # Extraer toda la estructura del men√∫
                menu_structure = await self.extract_menu_structure(page, category_prefix)
                
                if not menu_structure or not menu_structure.get('categorias'):
                    self.logger.warning("‚ö†Ô∏è No se encontr√≥ estructura del men√∫ o departamentos. Haciendo fallback a scraping directo...")
                    
                    # FALLBACK: Volver a la URL original y hacer scraping directo
                    original_url = response.url.split('?')[0]  # Remover par√°metros de scrapy
                    self.logger.info(f"üîÑ Fallback: Navegando de vuelta a la URL original: {original_url}")
                    
                    try:
                        await page.goto(original_url, wait_until="domcontentloaded", timeout=30000)
                        await page.wait_for_timeout(3000)
                        
                        # Hacer scraping directo con scroll infinito
                        self.logger.info("üìú Fallback: Iniciando scraping directo con scroll infinito...")
                        await self.await_products_loaded(page)
                        productos_cargados = await self.scroll_to_load_all_products(page)
                        self.logger.info(f"‚úÖ Fallback completado: {productos_cargados} productos extra√≠dos")
                        
                        content = await page.content()
                        from scrapy.http import HtmlResponse
                        updated_response = HtmlResponse(
                            url=original_url,
                            body=content,
                            encoding='utf-8'
                        )
                        for item in self.parse_products(updated_response):
                            yield item
                            
                    except Exception as fallback_error:
                        self.logger.error(f"‚ùå Error en fallback: {fallback_error}")
                    
                    await page.close()
                    return
                
                # Procesar cada categor√≠a del array temporal
                categorias = menu_structure.get('categorias', [])
                self.logger.info(f"üìã Procesando {len(categorias)} categor√≠as del men√∫...")
                
                for cat_info in categorias:
                    cat_nombre = cat_info.get('nombre', 'Sin nombre')
                    cat_href = cat_info.get('href', '')
                    subcategorias = cat_info.get('subcategorias', [])
                    
                    self.logger.info(f"üîÑ Procesando categor√≠a: '{cat_nombre}'")
                    
                    if subcategorias:
                        # Si hay subcategor√≠as, procesar cada una
                        self.logger.info(f"  üìä Encontradas {len(subcategorias)} subcategor√≠as")
                        
                        for subcat_info in subcategorias:
                            subcat_nombre = subcat_info.get('nombre', 'Sin nombre')
                            subcat_href = subcat_info.get('href', '')
                            
                            if not subcat_href:
                                self.logger.warning(f"  ‚ö†Ô∏è Subcategor√≠a sin href: {subcat_nombre}")
                                continue
                            
                            # Navegar a la subcategor√≠a
                            full_url = f"https://inkafarma.pe{subcat_href}" if subcat_href.startswith('/') else subcat_href
                            self.logger.info(f"  ‚û°Ô∏è Navegando a subcategor√≠a: '{subcat_nombre}' ‚Üí {full_url}")
                            
                            try:
                                await page.goto(full_url, wait_until="domcontentloaded", timeout=30000)
                                await page.wait_for_timeout(2000)
                                
                                # Verificar productos en esta subcategor√≠a
                                subcat_count = await self.get_product_count(page)
                                self.logger.info(f"  üìä Productos en '{subcat_nombre}': {subcat_count}")
                                
                                if subcat_count > 0:
                                    # Extraer productos
                                    await self.await_products_loaded(page)
                                    productos_cargados = await self.scroll_to_load_all_products(page)
                                    self.logger.info(f"  ‚úÖ Productos extra√≠dos: {productos_cargados}")
                                    
                                    content = await page.content()
                                    from scrapy.http import HtmlResponse
                                    updated_response = HtmlResponse(
                                        url=page.url,
                                        body=content,
                                        encoding='utf-8'
                                    )
                                    for item in self.parse_products(updated_response, subcat_nombre):
                                        yield item
                                
                            except Exception as e:
                                self.logger.error(f"  ‚ùå Error procesando subcategor√≠a '{subcat_nombre}': {e}")
                                continue
                    else:
                        # Si no hay subcategor√≠as, procesar la categor√≠a directamente
                        if not cat_href:
                            self.logger.warning(f"  ‚ö†Ô∏è Categor√≠a sin href: {cat_nombre}")
                            continue
                        
                        full_url = f"https://inkafarma.pe{cat_href}" if cat_href.startswith('/') else cat_href
                        self.logger.info(f"  ‚û°Ô∏è Navegando a categor√≠a: '{cat_nombre}' ‚Üí {full_url}")
                        
                        try:
                            await page.goto(full_url, wait_until="domcontentloaded", timeout=30000)
                            await page.wait_for_timeout(2000)
                            
                            cat_count = await self.get_product_count(page)
                            self.logger.info(f"  üìä Productos en '{cat_nombre}': {cat_count}")
                            
                            if cat_count > 0:
                                await self.await_products_loaded(page)
                                productos_cargados = await self.scroll_to_load_all_products(page)
                                self.logger.info(f"  ‚úÖ Productos extra√≠dos: {productos_cargados}")
                                
                                content = await page.content()
                                from scrapy.http import HtmlResponse
                                updated_response = HtmlResponse(
                                    url=page.url,
                                    body=content,
                                    encoding='utf-8'
                                )
                                for item in self.parse_products(updated_response, cat_nombre):
                                    yield item
                        
                        except Exception as e:
                            self.logger.error(f"  ‚ùå Error procesando categor√≠a '{cat_nombre}': {e}")
                            continue
                
                await page.close()

        except Exception as e:
            self.logger.error(f"‚ùå Error al procesar categor√≠a: {e}")
            if 'page' in locals():
                await page.close()

    async def get_product_count(self, page):
        """Obtener el n√∫mero de productos de la p√°gina usando el selector h3"""
        import re
        try:
            await page.wait_for_selector(inkafarma.SELECTOR_PRODUCT_COUNT_H3, timeout=3000)
            count_text = await page.text_content(inkafarma.SELECTOR_PRODUCT_COUNT_H3)
            match = re.search(r'(\d+)', count_text)
            if match:
                count = int(match.group(1))
                self.logger.info(f"üìù Encontrado en h3: {count} productos")
                return count
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è No se encontr√≥ h3 de conteo: {e}")
        self.logger.warning("‚ö†Ô∏è No se pudo obtener el conteo de productos")
        return 0

    async def navigate_subcategories(self, page, current_url):
        """Navegar por subcategor√≠as cuando hay >= 250 productos usando los selectores actualizados"""
        try:
            category_name = self.extract_category_from_url(current_url)
            category_prefix = category_name[:4].lower()
            self.logger.info(f"üîç Buscando subcategor√≠as que contengan: {category_prefix}")

            # Hacer clic en el men√∫ de categor√≠as
            await page.click(inkafarma.SELECTOR_CATEGORIES_MENU_BUTTON)
            await page.wait_for_timeout(2000)

            # Buscar subcategor√≠as
            subcategory_elements = await page.query_selector_all(inkafarma.SELECTOR_SUBCATEGORIES)
            self.logger.info(f"üìÇ Encontradas {len(subcategory_elements)} subcategor√≠as")

            for i, subcat in enumerate(subcategory_elements):
                # Obtener el texto del span dentro de la subcategor√≠a
                span = await subcat.query_selector(inkafarma.SELECTOR_SUBCATEGORY_SPAN)
                subcat_text = await span.text_content() if span else ""
                self.logger.info(f"üîÑ Subcategor√≠a {i+1}: {subcat_text}")
                # Verificar si el texto contiene el prefijo de la categor√≠a
                if category_prefix in subcat_text.lower():
                    self.logger.info(f"‚úÖ Subcategor√≠a relevante encontrada: {subcat_text}")
                    # Hacer clic en la subcategor√≠a
                    await subcat.click()
                    await page.wait_for_timeout(2000)
                    # Esperar a que se carguen los productos iniciales
                    await self.await_products_loaded(page)
                    # Realizar scroll infinito para cargar TODOS los productos
                    productos_cargados = await self.scroll_to_load_all_products(page)
                    self.logger.info(f"‚úÖ Total productos cargados en subcategor√≠a '{subcat_text}': {productos_cargados}")
                    # Obtener el HTML actualizado despu√©s del scroll
                    content = await page.content()
                    from scrapy.http import HtmlResponse
                    updated_response = HtmlResponse(
                        url=page.url,
                        body=content,
                        encoding='utf-8'
                    )
                    # Parsear todos los productos
                    for item in self.parse_products(updated_response, subcat_text):
                        yield item
                    # Volver al men√∫ para la siguiente subcategor√≠a
                    await page.click(inkafarma.SELECTOR_CATEGORIES_MENU_BUTTON)
                    await page.wait_for_timeout(1000)
            # Si no se encuentra ninguna subcategor√≠a relevante, loggear
            self.logger.info("üîç Procesamiento de subcategor√≠as completado")
        except Exception as e:
            self.logger.error(f"‚ùå Error navegando subcategor√≠as: {e}")
            self.logger.info("üîÑ Navegaci√≥n de subcategor√≠as fall√≥, continuando con scraping normal...")
            await self.await_products_loaded(page)
            productos_cargados = await self.scroll_to_load_all_products(page)
            self.logger.info(f"‚úÖ Scraping normal completado: {productos_cargados} productos cargados")
            content = await page.content()
            from scrapy.http import HtmlResponse
            updated_response = HtmlResponse(
                url=str(page.url),
                body=content,
                encoding='utf-8'
            )
            for item in self.parse_products(updated_response, None):
                yield item

    async def process_subcategory_products(self, page, subcategory_name):
        """Procesar productos de una subcategor√≠a espec√≠fica"""
        try:
            # Verificar si esta subcategor√≠a tambi√©n tiene >= 250 productos
            subcategory_count = await self.get_product_count(page)
            self.logger.info(f"üìä Subcategor√≠a '{subcategory_name}': {subcategory_count} productos")
            
            if subcategory_count >= 250:
                # Si la subcategor√≠a tambi√©n tiene muchos productos, podr√≠a tener sub-subcategor√≠as
                # Por ahora, procesamos normalmente pero se puede extender recursivamente
                self.logger.warning(f"‚ö†Ô∏è Subcategor√≠a '{subcategory_name}' tiene {subcategory_count} productos (>=250)")
            
            # Esperar a que se carguen los productos
            await self.await_products_loaded(page)
            
            # Realizar scroll para cargar todos los productos
            productos_cargados = await self.scroll_to_load_all_products(page)
            self.logger.info(f"‚úÖ Subcategor√≠a '{subcategory_name}': {productos_cargados} productos cargados")
            
            # Obtener el HTML y procesar productos
            content = await page.content()
            from scrapy.http import HtmlResponse
            updated_response = HtmlResponse(
                url=page.url,
                body=content,
                encoding='utf-8'
            )
            
            # Parsear productos con la subcategor√≠a como contexto
            for item in self.parse_products(updated_response, subcategory_name):
                yield item
                
        except Exception as e:
            self.logger.error(f"‚ùå Error procesando productos de subcategor√≠a '{subcategory_name}': {e}")

    async def await_products_loaded(self, page):
        try:
            # Esperar a que aparezcan los productos iniciales con timeout m√≠nimo
            await page.wait_for_selector(inkafarma.SELECTOR_PRODUCTO_CARD, timeout=8000)
            self.logger.info("‚úÖ Productos iniciales cargados")
            
            # Esperar tiempo m√≠nimo para asegurar renderizado completo
            await page.wait_for_timeout(1500)
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è No se pudieron cargar productos iniciales: {e}")
            # Esperar tiempo m√≠nimo y continuar
            await page.wait_for_timeout(2000)

    async def scroll_to_load_all_products(self, page):
        previous_height = -1
        scroll_attempts = 0
        max_attempts = 55
        stable_attempts = 0
        max_stable_attempts = 3
        
        while scroll_attempts < max_attempts:
            try:
                # Obtener la altura actual del contenedor de productos (sin esperar al selector)
                current_height = await page.evaluate(f"""
                    (() => {{
                        const container = document.querySelector('{inkafarma.SELECTOR_PRODUCTOS_CONTAINER}');
                        return container ? container.scrollHeight : document.body.scrollHeight;
                    }})()
                """)
                
                self.logger.info(f"üìè Scroll {scroll_attempts + 1}: Altura del contenedor: {current_height}px")
                
                # Si la altura no cambi√≥, verificar estabilidad
                if current_height == previous_height:
                    stable_attempts += 1
                    self.logger.info(f"üîÑ Altura estable {stable_attempts}/{max_stable_attempts}")
                    
                    if stable_attempts >= max_stable_attempts:
                        self.logger.info("üõë La altura del contenedor se estabiliz√≥ completamente. Scroll finalizado.")
                        break
                else:
                    # Si cambi√≥ la altura, resetear contador de estabilidad
                    stable_attempts = 0
                
                previous_height = current_height
                
                # Hacer scroll hasta el final de la p√°gina actual
                self.logger.info("üìú Haciendo scroll hasta el final...")
                await page.evaluate(f"window.scrollTo(0, {current_height})")
                
                # Esperar tiempo reducido entre scrolls
                await page.wait_for_timeout(1000)
                scroll_attempts += 1
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Error durante scroll {scroll_attempts + 1}: {e}")
                # Si falla el contenedor, intentar scroll b√°sico
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(1000)
                scroll_attempts += 1
        
        # Obtener el conteo final de productos solo despu√©s de que el tama√±o se estabilice
        try:
            productos_finales = await page.locator(inkafarma.SELECTOR_PRODUCTO_CARD).count()
            self.logger.info(f"üèÅ Scroll finalizado despu√©s de {scroll_attempts} intentos: {productos_finales} productos cargados")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Error obteniendo conteo final de productos: {e}")
            productos_finales = 0
        
        return productos_finales

    def parse_products(self, response, subcategory_name=None):
        """
        Extrae productos √öNICAMENTE despu√©s de que el scroll se haya completado y la p√°gina est√© estable.
        Utiliza el selector correcto: //fp-filtered-product-list//fp-product-large (Card de producto)
        """
        # Usar XPath para seleccionar todos los fp-product-large dentro de fp-filtered-product-list
        productos = response.xpath("//fp-filtered-product-list//fp-product-large")
        
        context = f" en subcategor√≠a '{subcategory_name}'" if subcategory_name else ""
        self.logger.info(f"üîç Procesando {len(productos)} productos encontrados{context} (DESPU√âS del scroll completo)")
        
        for i, producto in enumerate(productos):
            try:
                item = ScraperItem()
                
                # Extraer nombre del producto
                nombre_elem = producto.css(inkafarma.SELECTOR_PRODUCTO_NOMBRE + "::text").get()
                nombre = nombre_elem.strip() if nombre_elem else ""
                
                # Extraer presentaci√≥n/cantidad  
                presentacion_elem = producto.css(inkafarma.SELECTOR_PRODUCTO_PRESENTACION + "::text").get()
                presentacion = presentacion_elem.strip() if presentacion_elem else ""
                
                # Crear nombre completo como solicita el usuario: "Nombre - Presentaci√≥n"
                if nombre and presentacion:
                    nombre_completo = f"{nombre} - {presentacion}"
                else:
                    nombre_completo = nombre or "Sin nombre"
                
                item['name'] = nombre_completo
                
                # Extraer precio
                precio_elem = producto.css(inkafarma.SELECTOR_PRODUCTO_PRECIO + "::text").get()
                precio_text = precio_elem.strip() if precio_elem else "0"
                
                # Limpiar y procesar precio (puede venir como "S/ 5.20S/ 2.20")
                # Separar precios m√∫ltiples y tomar el precio m√°s bajo (oferta)
                precios = []
                if 'S/' in precio_text:
                    # Dividir por 'S/' y limpiar cada precio
                    partes = precio_text.split('S/')
                    for parte in partes:
                        if parte.strip():
                            # Remover todo excepto n√∫meros y punto decimal
                            precio_limpio = inkafarma.REGEX_SOLO_NUMEROS.sub('', parte.strip())
                            try:
                                if precio_limpio:
                                    precios.append(float(precio_limpio))
                            except ValueError:
                                continue
                
                # Tomar el precio m√°s bajo (generalmente el precio de oferta)
                precio = min(precios) if precios else 0.0
                
                item['price'] = precio
                
                # Calcular precio unitario basado en la presentaci√≥n
                unit_price = self.calculate_unit_price(precio, presentacion)
                item['unit_price'] = unit_price
                
                # Extraer cantidad y unidad de la presentaci√≥n
                quantity, unit_type = self.extract_quantity_and_unit(presentacion)
                item['total_unit_quantity'] = quantity
                item['unit_type'] = unit_type
                
                # Usar subcategor√≠a si est√° disponible, sino categor√≠a general
                item['category'] = subcategory_name if subcategory_name else "Farmacia"
                
                # Informaci√≥n comercial
                item['comercial_name'] = inkafarma.COMERCIAL_NAME
                item['comercial_id'] = inkafarma.COMERCIAL_ID
                
                yield item
                
            except Exception as e:
                self.logger.error(f"‚ùå Error procesando producto {i+1}: {e}")
                continue
        
        self.logger.info(f"‚úÖ Scraping completado: {len(productos)} productos extra√≠dos{context} (despu√©s del scroll completo)")
    
    def calculate_unit_price(self, precio_total, presentacion):
        try:
            match = inkafarma.REGEX_CANTIDAD_PRESENTACION.search(presentacion)
            if match:
                cantidad = float(match.group(1))
                if cantidad > 0:
                    return round(precio_total / cantidad, 2)
            return precio_total
        except Exception:
            return precio_total
    
    def extract_quantity_and_unit(self, presentacion):
        """Extrae cantidad y unidad de la presentaci√≥n"""
        try:
            match = inkafarma.REGEX_CANTIDAD_PRESENTACION.search(presentacion)
            if match:
                cantidad = float(match.group(1))
                unidad = match.group(2).lower()
                return cantidad, unidad
            # Si no encuentra patr√≥n espec√≠fico, asumir 1 unidad
            return 1.0, "un"
        except Exception:
            return 1.0, "un"
    
    def extract_category_from_url(self, url):
        """Extrae la categor√≠a desde la URL"""
        try:
            # URL format: https://inkafarma.pe/categoria/categoria-nombre
            if '/categoria/' in url:
                categoria = url.split('/categoria/')[-1]
                return categoria.replace('-', ' ').title()
            return "General"
        except Exception:
            return "General"